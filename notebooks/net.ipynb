{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prefix='unet_dev'\n",
    "model = mx.mod.Module(symbol=get_unet_symbol(), label_names=('label',))\n",
    "model.bind(data_shapes=[('data', (1, 3, 400, 400)),('label', (1, 1, 400, 400))])\n",
    "net_params = mx.initializer.Xavier()\n",
    "model.init_params(net_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'unet-net.gv.png'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_params(prefix+'-0001.params')\n",
    "model.symbol.save(prefix+'-symbol.json')\n",
    "# create network representation \n",
    "graph = mx.viz.plot_network(symbol=model.symbol)\n",
    "# save graph\n",
    "graph.format = 'png'\n",
    "graph.render('unet-net.gv', view=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in internals.list_outputs():\n",
    "    if 'output' in i:\n",
    "        # # get feature layer symbol out of internals\n",
    "        fea_symbol = internals[i]\n",
    "\n",
    "        # Make a new model by using an internal symbol. We can reuse all parameters from model we trained before\n",
    "        # In this case, we must set ```allow_extra_params``` to True\n",
    "        # Because we don't need params from FullyConnected symbol\n",
    "        feature_extractor = mx.model.FeedForward(ctx=mx.gpu(), \n",
    "                                                 symbol=fea_symbol,\n",
    "                                                 numpy_batch_size=1,\n",
    "                                                 arg_params=model.arg_params,\n",
    "                                                 aux_params=model.aux_params,\n",
    "                                                 allow_extra_params=True)\n",
    "        # predict feature\n",
    "        layer_info = feature_extractor.predict(batch)\n",
    "        print(i, layer_info.shape)\n",
    "#         m = layer_info.reshape(layer_info.shape[1], layer_info.shape[2], layer_info.shape[3])\n",
    "#         for j in range(layer_info.shape[1]):\n",
    "#             a = m[j, :, :].reshape(layer_info.shape[2], layer_info.shape[3])\n",
    "#             plt.figure(figsize=(5,5))\n",
    "#             plt.title(i+str(layer_info.shape))\n",
    "#             plt.imshow(a)\n",
    "#             plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def residual_unit(data, num_filter, stride, dim_match, name, bottle_neck=True, bn_mom=0.9, workspace=256, memonger=False):\n",
    "    \"\"\"Return ResNet Unit symbol for building ResNet\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : str\n",
    "        Input data\n",
    "    num_filter : int\n",
    "        Number of output channels\n",
    "    bnf : int\n",
    "        Bottle neck channels factor with regard to num_filter\n",
    "    stride : tupe\n",
    "        Stride used in convolution\n",
    "    dim_match : Boolen\n",
    "        True means channel number between input and output is the same, otherwise means differ\n",
    "    name : str\n",
    "        Base name of the operators\n",
    "    workspace : int\n",
    "        Workspace used in convolution operator\n",
    "    \"\"\"\n",
    "    if bottle_neck:\n",
    "        # the same as https://github.com/facebook/fb.resnet.torch#notes, a bit difference with origin paper\n",
    "        bn1 = mx.sym.BatchNorm(data=data, fix_gamma=False, eps=2e-5, momentum=bn_mom, name=name + '_bn1')\n",
    "        act1 = mx.sym.Activation(data=bn1, act_type='relu', name=name + '_relu1')\n",
    "        conv1 = mx.sym.Convolution(data=act1, num_filter=int(num_filter*0.25), kernel=(1,1), stride=(1,1), pad=(0,0),\n",
    "                                   no_bias=True, workspace=workspace, name=name + '_conv1')\n",
    "        bn2 = mx.sym.BatchNorm(data=conv1, fix_gamma=False, eps=2e-5, momentum=bn_mom, name=name + '_bn2')\n",
    "        act2 = mx.sym.Activation(data=bn2, act_type='relu', name=name + '_relu2')\n",
    "        conv2 = mx.sym.Convolution(data=act2, num_filter=int(num_filter*0.25), kernel=(3,3), stride=stride, pad=(1,1),\n",
    "                                   no_bias=True, workspace=workspace, name=name + '_conv2')\n",
    "        bn3 = mx.sym.BatchNorm(data=conv2, fix_gamma=False, eps=2e-5, momentum=bn_mom, name=name + '_bn3')\n",
    "        act3 = mx.sym.Activation(data=bn3, act_type='relu', name=name + '_relu3')\n",
    "        conv3 = mx.sym.Convolution(data=act3, num_filter=num_filter, kernel=(1,1), stride=(1,1), pad=(0,0), no_bias=True,\n",
    "                                   workspace=workspace, name=name + '_conv3')\n",
    "        if dim_match:\n",
    "            shortcut = data\n",
    "        else:\n",
    "            shortcut = mx.sym.Convolution(data=act1, num_filter=num_filter, kernel=(1,1), stride=stride, no_bias=True,\n",
    "                                            workspace=workspace, name=name+'_sc')\n",
    "        if memonger:\n",
    "            shortcut._set_attr(mirror_stage='True')\n",
    "        return conv3 + shortcut\n",
    "    else:\n",
    "        bn1 = mx.sym.BatchNorm(data=data, fix_gamma=False, momentum=bn_mom, eps=2e-5, name=name + '_bn1')\n",
    "        act1 = mx.sym.Activation(data=bn1, act_type='relu', name=name + '_relu1')\n",
    "        conv1 = mx.sym.Convolution(data=act1, num_filter=num_filter, kernel=(3,3), stride=stride, pad=(1,1),\n",
    "                                      no_bias=True, workspace=workspace, name=name + '_conv1')\n",
    "        bn2 = mx.sym.BatchNorm(data=conv1, fix_gamma=False, momentum=bn_mom, eps=2e-5, name=name + '_bn2')\n",
    "        act2 = mx.sym.Activation(data=bn2, act_type='relu', name=name + '_relu2')\n",
    "        conv2 = mx.sym.Convolution(data=act2, num_filter=num_filter, kernel=(3,3), stride=(1,1), pad=(1,1),\n",
    "                                      no_bias=True, workspace=workspace, name=name + '_conv2')\n",
    "        if dim_match:\n",
    "            shortcut = data\n",
    "        else:\n",
    "            shortcut = mx.sym.Convolution(data=act1, num_filter=num_filter, kernel=(1,1), stride=stride, no_bias=True,\n",
    "                                            workspace=workspace, name=name+'_sc')\n",
    "        if memonger:\n",
    "            shortcut._set_attr(mirror_stage='True')\n",
    "        return conv2 + shortcut\n",
    "\n",
    "def resnet(units, num_stages, filter_list, num_classes, image_shape, bottle_neck=True, bn_mom=0.9, workspace=256, memonger=False):\n",
    "    \"\"\"Return ResNet symbol of\n",
    "    Parameters\n",
    "    ----------\n",
    "    units : list\n",
    "        Number of units in each stage\n",
    "    num_stages : int\n",
    "        Number of stage\n",
    "    filter_list : list\n",
    "        Channel size of each stage\n",
    "    num_classes : int\n",
    "        Ouput size of symbol\n",
    "    dataset : str\n",
    "        Dataset type, only cifar10 and imagenet supports\n",
    "    workspace : int\n",
    "        Workspace used in convolution operator\n",
    "    \"\"\"\n",
    "    num_unit = len(units)\n",
    "    assert(num_unit == num_stages)\n",
    "    data = mx.sym.Variable(name='data')\n",
    "    data = mx.sym.BatchNorm(data=data, fix_gamma=True, eps=2e-5, momentum=bn_mom, name='bn_data')\n",
    "    (nchannel, height, width) = image_shape\n",
    "    if height <= 32:            # such as cifar10\n",
    "        body = mx.sym.Convolution(data=data, num_filter=filter_list[0], kernel=(3, 3), stride=(1,1), pad=(1, 1),\n",
    "                                  no_bias=True, name=\"conv0\", workspace=workspace)\n",
    "    else:                       # often expected to be 224 such as imagenet\n",
    "        body = mx.sym.Convolution(data=data, num_filter=filter_list[0], kernel=(7, 7), stride=(2,2), pad=(3, 3),\n",
    "                                  no_bias=True, name=\"conv0\", workspace=workspace)\n",
    "        body = mx.sym.BatchNorm(data=body, fix_gamma=False, eps=2e-5, momentum=bn_mom, name='bn0')\n",
    "        body = mx.sym.Activation(data=body, act_type='relu', name='relu0')\n",
    "        body = mx.symbol.Pooling(data=body, kernel=(3, 3), stride=(2,2), pad=(1,1), pool_type='max')\n",
    "\n",
    "    for i in range(num_stages):\n",
    "        body = residual_unit(body, filter_list[i+1], (1 if i==0 else 2, 1 if i==0 else 2), False,\n",
    "                             name='stage%d_unit%d' % (i + 1, 1), bottle_neck=bottle_neck, workspace=workspace,\n",
    "                             memonger=memonger)\n",
    "        for j in range(units[i]-1):\n",
    "            body = residual_unit(body, filter_list[i+1], (1,1), True, name='stage%d_unit%d' % (i + 1, j + 2),\n",
    "                                 bottle_neck=bottle_neck, workspace=workspace, memonger=memonger)\n",
    "    bn1 = mx.sym.BatchNorm(data=body, fix_gamma=False, eps=2e-5, momentum=bn_mom, name='bn1')\n",
    "    relu1 = mx.sym.Activation(data=bn1, act_type='relu', name='relu1')\n",
    "    # Although kernel is not used here when global_pool=True, we should put one\n",
    "    pool1 = mx.symbol.Pooling(data=relu1, global_pool=True, kernel=(7, 7), pool_type='avg', name='pool1')\n",
    "    flat = mx.symbol.Flatten(data=pool1)\n",
    "    fc1 = mx.symbol.FullyConnected(data=flat, num_hidden=num_classes, name='fc1')\n",
    "    return mx.symbol.SoftmaxOutput(data=fc1, name='softmax')\n",
    "\n",
    "def get_resnet_symbol(num_classes, num_layers, image_shape, conv_workspace=256, **kwargs):\n",
    "    \"\"\"\n",
    "    Adapted from https://github.com/tornadomeet/ResNet/blob/master/train_resnet.py\n",
    "    Original author Wei Wu\n",
    "    \"\"\"\n",
    "    image_shape = [int(l) for l in image_shape.split(',')]\n",
    "    (nchannel, height, width) = image_shape\n",
    "    if height <= 28:\n",
    "        num_stages = 3\n",
    "        if (num_layers-2) % 9 == 0 and num_layers >= 164:\n",
    "            per_unit = [(num_layers-2)//9]\n",
    "            filter_list = [16, 64, 128, 256]\n",
    "            bottle_neck = True\n",
    "        elif (num_layers-2) % 6 == 0 and num_layers < 164:\n",
    "            per_unit = [(num_layers-2)//6]\n",
    "            filter_list = [16, 16, 32, 64]\n",
    "            bottle_neck = False\n",
    "        else:\n",
    "            raise ValueError(\"no experiments done on num_layers {}, you can do it youself\".format(num_layers))\n",
    "        units = per_unit * num_stages\n",
    "    else:\n",
    "        if num_layers >= 50:\n",
    "            filter_list = [64, 256, 512, 1024, 2048]\n",
    "            bottle_neck = True\n",
    "        else:\n",
    "            filter_list = [64, 64, 128, 256, 512]\n",
    "            bottle_neck = False\n",
    "        num_stages = 4\n",
    "        if num_layers == 18:\n",
    "            units = [2, 2, 2, 2]\n",
    "        elif num_layers == 34:\n",
    "            units = [3, 4, 6, 3]\n",
    "        elif num_layers == 50:\n",
    "            units = [3, 4, 6, 3]\n",
    "        elif num_layers == 101:\n",
    "            units = [3, 4, 23, 3]\n",
    "        elif num_layers == 152:\n",
    "            units = [3, 8, 36, 3]\n",
    "        elif num_layers == 200:\n",
    "            units = [3, 24, 36, 3]\n",
    "        elif num_layers == 269:\n",
    "            units = [3, 30, 48, 8]\n",
    "        else:\n",
    "            raise ValueError(\"no experiments done on num_layers {}, you can do it youself\".format(num_layers))\n",
    "\n",
    "    return resnet(units       = units,\n",
    "                  num_stages  = num_stages,\n",
    "                  filter_list = filter_list,\n",
    "                  num_classes = num_classes,\n",
    "                  image_shape = image_shape,\n",
    "                  bottle_neck = bottle_neck,\n",
    "                  workspace   = conv_workspace)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = pd.read_csv('input/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a.MultipolygonWKT = 'MULTIPOLYGON EMPTY'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a.to_csv('input/submission_empty.csv', index='False')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "http://gis.stackexchange.com/questions/187877/how-to-polygonize-raster-to-shapely-polygons"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
